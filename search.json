[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "My Ai-Log",
    "section": "",
    "text": "03 - The forward and backward passes\n\n\n\n\n\n\n\nfastai\n\n\ncourse22p2\n\n\n\n\n\n\n\n\n\n\n\nFeb 26, 2023\n\n\nNiyazi Kemer\n\n\n\n\n\n\n  \n\n\n\n\n02 - Mean Shift\n\n\n\n\n\n\n\nfastai\n\n\ncourse22p2\n\n\n\n\n\n\n\n\n\n\n\nFeb 8, 2023\n\n\nNiyazi Kemer\n\n\n\n\n\n\n  \n\n\n\n\n01 - Matrix multiplication from foundations\n\n\n\n\n\n\n\nfastai\n\n\ncourse22p2\n\n\n\n\n\n\n\n\n\n\n\nFeb 6, 2023\n\n\nNiyazi Kemer\n\n\n\n\n\n\n  \n\n\n\n\nTiny bug world with neuro evolution (2018)\n\n\n\n\n\n\n\nneuro evolution\n\n\n\n\n\n\n\n\n\n\n\nJan 15, 2022\n\n\nNiyazi Kemer\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/course22p2/01_matmul.html",
    "href": "posts/course22p2/01_matmul.html",
    "title": "01 - Matrix multiplication from foundations",
    "section": "",
    "text": "This is not my content it’s a part of Fastai’s From Deep Learning Foundations to Stable Diffusion course. I add some notes for me to understand better thats all. For the source check Fastai course page."
  },
  {
    "objectID": "posts/course22p2/01_matmul.html#matrix-multiplication-from-foundations",
    "href": "posts/course22p2/01_matmul.html#matrix-multiplication-from-foundations",
    "title": "01 - Matrix multiplication from foundations",
    "section": "Matrix multiplication from foundations",
    "text": "Matrix multiplication from foundations\nThe foundations we’ll assume throughout this course are:\n\nPython\nmatplotlib\nThe Python standard library\nJupyter notebooks and nbdev\n\n\nfrom pathlib import Path\nimport pickle, gzip, math, os, time, shutil, matplotlib as mpl, matplotlib.pyplot as plt"
  },
  {
    "objectID": "posts/course22p2/01_matmul.html#get-data",
    "href": "posts/course22p2/01_matmul.html#get-data",
    "title": "01 - Matrix multiplication from foundations",
    "section": "Get data",
    "text": "Get data\n\nMNIST_URL='https://github.com/mnielsen/neural-networks-and-deep-learning/blob/master/data/mnist.pkl.gz?raw=true'\npath_data = Path('data')\npath_data.mkdir(exist_ok=True)\npath_gz = path_data/'mnist.pkl.gz'\n\nurlretrieve - (read the docs!)\n\nfrom urllib.request import urlretrieve\nif not path_gz.exists(): urlretrieve(MNIST_URL, path_gz)\n\n\n!ls -l data\n\ntotal 16656\n-rw-rw-r-- 1 niyazi niyazi 17051982 Şub  5 11:17 mnist.pkl.gz\n\n\n\nwith gzip.open(path_gz, 'rb') as f: ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding='latin-1')\n\n\nlst1 = list(x_train[0])\nvals = lst1[200:210]\nvals\n\n[0.0,\n 0.0,\n 0.0,\n 0.19140625,\n 0.9296875,\n 0.98828125,\n 0.98828125,\n 0.98828125,\n 0.98828125,\n 0.98828125]\n\n\n\ndef chunks(x, sz):\n    for i in range(0, len(x), sz): yield x[i:i+sz]\n\n\nlist(chunks(vals, 5))\n\n[[0.0, 0.0, 0.0, 0.19140625, 0.9296875],\n [0.98828125, 0.98828125, 0.98828125, 0.98828125, 0.98828125]]\n\n\n\n\n\n\n\n\nChoosing colormaps in Matplotlib\n\n\n\nhttps://matplotlib.org/stable/tutorials/colors/colormaps.html\n\n\n\n# this cahanges the colormap\nmpl.rcParams['image.cmap'] = 'magma'\n# mpl.pyplot == plt.imshow\nmpl.pyplot.imshow(list(chunks(lst1, 28)));\n\n\n\n\nislice\n\nfrom itertools import islice\n\n\nit = iter(vals)\nislice(it, 5)\n\n<itertools.islice>\n\n\n\nlist(islice(it, 5))\n\n[0.0, 0.0, 0.0, 0.19140625, 0.9296875]\n\n\n\nlist(islice(it, 5))\n\n[0.98828125, 0.98828125, 0.98828125, 0.98828125, 0.98828125]\n\n\n\nlist(islice(it, 5))\n\n[]\n\n\n\n\n\n\n\n\nIter-callable usage\n\n\n\nif a callable passed to a iter(lambda) then it runs again and again until it thit the sentinel that is [] at this time\n\n\n\niter(lambda: list(islice(it, 28)), [])\n\n<callable_iterator>\n\n\n\nit = iter(lst1)\nimg = list(iter(lambda: list(islice(it, 28)), []))\n\n\nplt.imshow(img);"
  },
  {
    "objectID": "posts/course22p2/01_matmul.html#matrix-and-tensor",
    "href": "posts/course22p2/01_matmul.html#matrix-and-tensor",
    "title": "01 - Matrix multiplication from foundations",
    "section": "Matrix and tensor",
    "text": "Matrix and tensor\n\nimg[20][15]\n\n0.98828125\n\n\n\nclass Matrix:\n    def __init__(self, xs): self.xs = xs\n    def __getitem__(self, idxs): return self.xs[idxs[0]][idxs[1]]\n\n\nm = Matrix(img)\nm[20,15]\n\n0.98828125\n\n\n\nimport torch\nfrom torch import tensor\n\n\ntensor([1,2,3])\n\ntensor([1, 2, 3])\n\n\n\nx_train,y_train,x_valid,y_valid = map(tensor, (x_train,y_train,x_valid,y_valid))\nx_train.shape\n\ntorch.Size([50000, 784])\n\n\n\nx_train.type()\n\n'torch.FloatTensor'\n\n\nTensor\n\nimgs = x_train.reshape((-1,28,28))\nimgs.shape\n\ntorch.Size([50000, 28, 28])\n\n\n\nplt.imshow(imgs[0]);\n\n\n\n\n\nimgs[0,20,15]\n\ntensor(0.99)\n\n\n\nn,c = x_train.shape\ny_train, y_train.shape\n\n(tensor([5, 0, 4,  ..., 8, 4, 8]), torch.Size([50000]))\n\n\n\nmin(y_train),max(y_train)\n\n(tensor(0), tensor(9))\n\n\n\ny_train.min(), y_train.max()\n\n(tensor(0), tensor(9))"
  },
  {
    "objectID": "posts/course22p2/01_matmul.html#random-numbers",
    "href": "posts/course22p2/01_matmul.html#random-numbers",
    "title": "01 - Matrix multiplication from foundations",
    "section": "Random numbers",
    "text": "Random numbers\nQuantum random numbers from The Australian National University https://qrng.anu.edu.au/\nCloudFlare random number generator. https://blog.cloudflare.com/randomness-101-lavarand-in-production/\nBased on the Wichmann Hill algorithm used before Python 2.3.\n\nrnd_state = None\ndef seed(a):\n    global rnd_state\n    a, x = divmod(a, 30268)\n    a, y = divmod(a, 30306)\n    a, z = divmod(a, 30322)\n    rnd_state = int(x)+1, int(y)+1, int(z)+1\n\n\nseed(457428938475)\nrnd_state\n\n(4976, 20238, 499)\n\n\n\ndef rand():\n    global rnd_state\n    x, y, z = rnd_state\n    x = (171 * x) % 30269\n    y = (172 * y) % 30307\n    z = (170 * z) % 30323\n    rnd_state = x,y,z\n    return (x/30269 + y/30307 + z/30323) % 1.0\n\n\nrand(),rand(),rand()\n\n(0.7645251082582081, 0.7920889799553945, 0.06912886811267205)\n\n\n\nif os.fork(): print(f'In parent: {rand()}')\nelse:\n    print(f'In child: {rand()}')\n    os._exit(os.EX_OK)\n\nIn parent: 0.9559050644103264\nIn child: 0.9559050644103264\n\n\n\nif os.fork(): print(f'In parent: {torch.rand(1)}')\nelse:\n    print(f'In child: {torch.rand(1)}')\n    os._exit(os.EX_OK)\n\nIn parent: tensor([0.93])\nIn child: tensor([0.93])\n\n\n\nplt.plot([rand() for _ in range(50)]);\n\n\n\n\n\nplt.hist([rand() for _ in range(10000)]);\n\n\n\n\n\n%timeit -n 10 list(chunks([rand() for _ in range(7840)], 10))\n\n1.55 ms ± 8.41 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n\n\n\n%timeit -n 10 torch.randn(784,10)\n\n26.9 µs ± 13.2 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)"
  },
  {
    "objectID": "posts/course22p2/01_matmul.html#matrix-multiplication",
    "href": "posts/course22p2/01_matmul.html#matrix-multiplication",
    "title": "01 - Matrix multiplication from foundations",
    "section": "Matrix multiplication",
    "text": "Matrix multiplication\n\ntorch.manual_seed(1)\nweights = torch.randn(784,10)\nbias = torch.zeros(10)\n\n\nm1 = x_valid[:5]\nm2 = weights\n\n\nm1.shape,m2.shape\n\n(torch.Size([5, 784]), torch.Size([784, 10]))\n\n\n\nar,ac = m1.shape # n_rows * n_cols\nbr,bc = m2.shape\n(ar,ac),(br,bc)\n\n((5, 784), (784, 10))\n\n\n\nt1 = torch.zeros(ar, bc)\nt1.shape\n\ntorch.Size([5, 10])\n\n\n\nfor i in range(ar):         # 5\n    for j in range(bc):     # 10\n        for k in range(ac): # 784\n            t1[i,j] += m1[i,k] * m2[k,j]\n\n\n\n\n\n\n\nFor a better visibility change the linewidth from 80 to 140\n\n\n\n\n\n\n\ntorch.set_printoptions(precision=2, linewidth=80, sci_mode=False)\nt1\n\ntensor([[-10.94,  -0.68,  -7.00,  -4.01,  -2.09,  -3.36,   3.91,  -3.44, -11.47,\n          -2.12],\n        [ 14.54,   6.00,   2.89,  -4.08,   6.59, -14.74,  -9.28,   2.16, -15.28,\n          -2.68],\n        [  2.22,  -3.22,  -4.80,  -6.05,  14.17,  -8.98,  -4.79,  -5.44, -20.68,\n          13.57],\n        [ -6.71,   8.90,  -7.46,  -7.90,   2.70,  -4.73, -11.03, -12.98,  -6.44,\n           3.64],\n        [ -2.44,  -6.40,  -2.40,  -9.04,  11.18,  -5.77,  -8.92,  -3.79,  -8.98,\n           5.28]])\n\n\n\nt1.shape\n\ntorch.Size([5, 10])\n\n\n\n\n\n\n\n\nThe same content with 140 characters\n\n\n\n\n\n\n\ntorch.set_printoptions(precision=2, linewidth=140, sci_mode=False)\nt1\n\ntensor([[-10.94,  -0.68,  -7.00,  -4.01,  -2.09,  -3.36,   3.91,  -3.44, -11.47,  -2.12],\n        [ 14.54,   6.00,   2.89,  -4.08,   6.59, -14.74,  -9.28,   2.16, -15.28,  -2.68],\n        [  2.22,  -3.22,  -4.80,  -6.05,  14.17,  -8.98,  -4.79,  -5.44, -20.68,  13.57],\n        [ -6.71,   8.90,  -7.46,  -7.90,   2.70,  -4.73, -11.03, -12.98,  -6.44,   3.64],\n        [ -2.44,  -6.40,  -2.40,  -9.04,  11.18,  -5.77,  -8.92,  -3.79,  -8.98,   5.28]])\n\n\n\nimport numpy as np\nnp.set_printoptions(precision=2, linewidth=140)\n\n\ndef matmul(a,b):\n    (ar,ac),(br,bc) = a.shape,b.shape\n    c = torch.zeros(ar, bc)\n    for i in range(ar):\n        for j in range(bc):\n            for k in range(ac): c[i,j] += a[i,k] * b[k,j]\n    return c\n\n\n%time _=matmul(m1, m2)\n\nCPU times: user 227 ms, sys: 0 ns, total: 227 ms\nWall time: 227 ms\n\n\n\nar*bc*ac\n\n39200"
  },
  {
    "objectID": "posts/course22p2/01_matmul.html#numba",
    "href": "posts/course22p2/01_matmul.html#numba",
    "title": "01 - Matrix multiplication from foundations",
    "section": "Numba",
    "text": "Numba\n\nfrom numba import njit\n\n\n@njit\ndef dot(a,b):\n    res = 0.\n    for i in range(len(a)): res+=a[i]*b[i]\n    return res\n\n\nfrom numpy import array\n\n\n%time dot(array([1.,2,3]),array([2.,3,4]))\n\nCPU times: user 47.3 ms, sys: 3.69 ms, total: 50.9 ms\nWall time: 50.8 ms\n\n\n20.0\n\n\n\n%time dot(array([1.,2,3]),array([2.,3,4]))\n\nCPU times: user 16 µs, sys: 0 ns, total: 16 µs\nWall time: 18.1 µs\n\n\n20.0\n\n\nNow only two of our loops are running in Python, not three:\n\ndef matmul(a,b):\n    (ar,ac),(br,bc) = a.shape,b.shape\n    c = torch.zeros(ar, bc)\n    for i in range(ar):\n        for j in range(bc): c[i,j] = dot(a[i,:], b[:,j])\n    return c\n\n\nm1a,m2a = m1.numpy(),m2.numpy()\n\n\nfrom fastcore.test import *\n\n\ntest_close(t1,matmul(m1a, m2a))\n\n\n%timeit -n 50 matmul(m1a,m2a)\n\n148 µs ± 14.6 µs per loop (mean ± std. dev. of 7 runs, 50 loops each)"
  },
  {
    "objectID": "posts/course22p2/01_matmul.html#elementwise-ops",
    "href": "posts/course22p2/01_matmul.html#elementwise-ops",
    "title": "01 - Matrix multiplication from foundations",
    "section": "Elementwise ops",
    "text": "Elementwise ops\nnk allways right to left no operator precedence\nTryAPL\n\na = tensor([10., 6, -4])\nb = tensor([2., 8, 7])\na,b\n\n(tensor([10.,  6., -4.]), tensor([2., 8., 7.]))\n\n\n\na + b\n\ntensor([12., 14.,  3.])\n\n\n\n(a < b).float().mean()\n\ntensor(0.67)\n\n\n\nm = tensor([[1., 2, 3], [4,5,6], [7,8,9]]); m\n\ntensor([[1., 2., 3.],\n        [4., 5., 6.],\n        [7., 8., 9.]])\n\n\nFrobenius norm:\n\\[\\| A \\|_F = \\left( \\sum_{i,j=1}^n | a_{ij} |^2 \\right)^{1/2}\\]\nHint: you don’t normally need to write equations in LaTeX yourself, instead, you can click ‘edit’ in Wikipedia and copy the LaTeX from there (which is what I did for the above equation). Or on arxiv.org, click “Download: Other formats” in the top right, then “Download source”; rename the downloaded file to end in .tgz if it doesn’t already, and you should find the source there, including the equations to copy and paste. This is the source LaTeX that I pasted to render the equation above:\n$$\\| A \\|_F = \\left( \\sum_{i,j=1}^n | a_{ij} |^2 \\right)^{1/2}$$\n\nsf = (m*m).sum()\nsf\n\ntensor(285.)\n\n\n\nsf.sqrt()\n\ntensor(16.88)\n\n\n\nm[2,:],m[:,2]\n\n(tensor([7., 8., 9.]), tensor([3., 6., 9.]))\n\n\n\nm[2]\n\ntensor([7., 8., 9.])\n\n\n\ndef matmul(a,b):\n    (ar,ac),(br,bc) = a.shape,b.shape\n    c = torch.zeros(ar, bc)\n    for i in range(ar):\n        for j in range(bc): c[i,j] = (a[i,:] * b[:,j]).sum()\n    return c\n\n\ntest_close(t1,matmul(m1, m2))\n\n\n%timeit -n 50 _=matmul(m1, m2)\n\n279 µs ± 2.53 µs per loop (mean ± std. dev. of 7 runs, 50 loops each)\n\n\n\ndef matmul(a,b):\n    (ar,ac),(br,bc) = a.shape,b.shape\n    c = torch.zeros(ar, bc)\n    for i in range(ar):\n        for j in range(bc): c[i,j] = torch.dot(a[i,:], b[:,j])\n    return c\n\n\ntest_close(t1,matmul(m1, m2))\n\n\n%timeit -n 50 _=matmul(m1, m2)\n\n236 µs ± 3.12 µs per loop (mean ± std. dev. of 7 runs, 50 loops each)"
  },
  {
    "objectID": "posts/course22p2/01_matmul.html#broadcasting",
    "href": "posts/course22p2/01_matmul.html#broadcasting",
    "title": "01 - Matrix multiplication from foundations",
    "section": "Broadcasting",
    "text": "Broadcasting\nThe term broadcasting describes how arrays with different shapes are treated during arithmetic operations.\nFrom the Numpy Documentation:\nThe term broadcasting describes how numpy treats arrays with \ndifferent shapes during arithmetic operations. Subject to certain \nconstraints, the smaller array is “broadcast” across the larger \narray so that they have compatible shapes. Broadcasting provides a \nmeans of vectorizing array operations so that looping occurs in C\ninstead of Python. It does this without making needless copies of \ndata and usually leads to efficient algorithm implementations.\nIn addition to the efficiency of broadcasting, it allows developers to write less code, which typically leads to fewer errors.\nThis section was adapted from Chapter 4 of the fast.ai Computational Linear Algebra course.\n\nBroadcasting with a scalar\n\na\n\ntensor([10.,  6., -4.])\n\n\n\na > 0\n\ntensor([ True,  True, False])\n\n\nHow are we able to do a > 0? 0 is being broadcast to have the same dimensions as a.\nFor instance you can normalize our dataset by subtracting the mean (a scalar) from the entire data set (a matrix) and dividing by the standard deviation (another scalar), using broadcasting.\nOther examples of broadcasting with a scalar:\n\na + 1\n\ntensor([11.,  7., -3.])\n\n\n\nm\n\ntensor([[1., 2., 3.],\n        [4., 5., 6.],\n        [7., 8., 9.]])\n\n\n\n2*m\n\ntensor([[ 2.,  4.,  6.],\n        [ 8., 10., 12.],\n        [14., 16., 18.]])\n\n\n\n\nBroadcasting a vector to a matrix\nAlthough broadcasting a scalar is an idea that dates back to APL, the more powerful idea of broadcasting across higher rank tensors comes from a little known language called Yorick.\nWe can also broadcast a vector to a matrix:\n\nc = tensor([10.,20,30]); c\n\ntensor([10., 20., 30.])\n\n\n\nm\n\ntensor([[1., 2., 3.],\n        [4., 5., 6.],\n        [7., 8., 9.]])\n\n\n\nm.shape,c.shape\n\n(torch.Size([3, 3]), torch.Size([3]))\n\n\n\nm + c\n\ntensor([[11., 22., 33.],\n        [14., 25., 36.],\n        [17., 28., 39.]])\n\n\n\nc + m\n\ntensor([[11., 22., 33.],\n        [14., 25., 36.],\n        [17., 28., 39.]])\n\n\n\nt = c.expand_as(m)\n\n\nt\n\ntensor([[10., 20., 30.],\n        [10., 20., 30.],\n        [10., 20., 30.]])\n\n\n\nm + t\n\ntensor([[11., 22., 33.],\n        [14., 25., 36.],\n        [17., 28., 39.]])\n\n\nWe don’t really copy the rows, but it looks as if we did. In fact, the rows are given a stride of 0.\n\nt.storage()\n\n 10.0\n 20.0\n 30.0\n[torch.storage.TypedStorage(dtype=torch.float32, device=cpu) of size 3]\n\n\n\nt.stride(), t.shape\n\n((0, 1), torch.Size([3, 3]))\n\n\nYou can index with the special value [None] or use unsqueeze() to convert a 1-dimensional array into a 2-dimensional array (although one of those dimensions has value 1).\n\nc.shape\n\ntorch.Size([3])\n\n\n\nc.unsqueeze(0), c[None, :]\n\n(tensor([[10., 20., 30.]]), tensor([[10., 20., 30.]]))\n\n\n\nc.shape, c.unsqueeze(0).shape\n\n(torch.Size([3]), torch.Size([1, 3]))\n\n\n\nc.unsqueeze(1), c[:, None]\n\n(tensor([[10.],\n         [20.],\n         [30.]]),\n tensor([[10.],\n         [20.],\n         [30.]]))\n\n\n\nc.shape, c.unsqueeze(1).shape\n\n(torch.Size([3]), torch.Size([3, 1]))\n\n\nYou can always skip trailling ‘:’s. And’…’ means ‘all preceding dimensions’\n\nc[None].shape,c[...,None].shape\n\n(torch.Size([1, 3]), torch.Size([3, 1]))\n\n\n\nc[:,None].expand_as(m)\n\ntensor([[10., 10., 10.],\n        [20., 20., 20.],\n        [30., 30., 30.]])\n\n\n\nm + c[:,None]\n\ntensor([[11., 12., 13.],\n        [24., 25., 26.],\n        [37., 38., 39.]])\n\n\n\nm + c[None,:]\n\ntensor([[11., 22., 33.],\n        [14., 25., 36.],\n        [17., 28., 39.]])\n\n\n\n\nBroadcasting Rules\n\nc[None,:]\n\ntensor([[10., 20., 30.]])\n\n\n\nc[None,:].shape\n\ntorch.Size([1, 3])\n\n\n\nc[:,None]\n\ntensor([[10.],\n        [20.],\n        [30.]])\n\n\n\nc[:,None].shape\n\ntorch.Size([3, 1])\n\n\n\nc[None,:] * c[:,None]\n\ntensor([[100., 200., 300.],\n        [200., 400., 600.],\n        [300., 600., 900.]])\n\n\n\nc[None] > c[:,None]\n\ntensor([[False,  True,  True],\n        [False, False,  True],\n        [False, False, False]])\n\n\n\nm*m\n\ntensor([[ 1.,  4.,  9.],\n        [16., 25., 36.],\n        [49., 64., 81.]])\n\n\nWhen operating on two arrays/tensors, Numpy/PyTorch compares their shapes element-wise. It starts with the trailing dimensions, and works its way forward. Two dimensions are compatible when\n\nthey are equal, or\none of them is 1, in which case that dimension is broadcasted to make it the same size\n\nArrays do not need to have the same number of dimensions. For example, if you have a 256*256*3 array of RGB values, and you want to scale each color in the image by a different value, you can multiply the image by a one-dimensional array with 3 values. Lining up the sizes of the trailing axes of these arrays according to the broadcast rules, shows that they are compatible:\nImage  (3d array): 256 x 256 x 3\nScale  (1d array):             3\nResult (3d array): 256 x 256 x 3\nThe numpy documentation includes several examples of what dimensions can and can not be broadcast together."
  },
  {
    "objectID": "posts/course22p2/01_matmul.html#matmul-with-broadcasting",
    "href": "posts/course22p2/01_matmul.html#matmul-with-broadcasting",
    "title": "01 - Matrix multiplication from foundations",
    "section": "Matmul with broadcasting",
    "text": "Matmul with broadcasting\ndigit is the first digit in the dataset\n\ndigit = m1[0]\ndigit.shape,m2.shape\n\n(torch.Size([784]), torch.Size([784, 10]))\n\n\n\nm2.shape\n\ntorch.Size([784, 10])\n\n\n\ndigit[:,None].shape\n\ntorch.Size([784, 1])\n\n\n\ndigit[:,None].expand_as(m2).shape\n\ntorch.Size([784, 10])\n\n\n\n(digit[:,None]*m2).shape\n\ntorch.Size([784, 10])\n\n\n\ndef matmul(a,b):\n    (ar,ac),(br,bc) = a.shape,b.shape\n    c = torch.zeros(ar, bc)\n    for i in range(ar):\n#       c[i,j] = (a[i,:] * b[:,j]).sum()      # previous version\n        c[i]   = (a[i,:,None] * b).sum(dim=0) # broadcast version\n    return c\n\n\ntest_close(t1,matmul(m1, m2))\n\n\n%timeit -n 50 _=matmul(m1, m2)\n\n70.1 µs ± 1.97 µs per loop (mean ± std. dev. of 7 runs, 50 loops each)\n\n\nOur time has gone from ~500ms to <0.1ms, an over 5000x improvement! We can run on the whole dataset now.\n\ntr = matmul(x_train, weights)\ntr\n\ntensor([[  0.96,  -2.96,  -2.11,  ..., -15.09, -17.69,   0.60],\n        [  6.89,  -0.34,   0.79,  ..., -17.13, -25.36,  16.23],\n        [-10.18,   7.38,   4.13,  ...,  -6.73,  -6.79,  -1.58],\n        ...,\n        [  7.40,   7.64,  -3.50,  ...,  -1.02, -16.22,   2.07],\n        [  3.25,   9.52,  -9.37,  ...,   2.98, -19.58,  -1.96],\n        [ 15.70,   4.12,  -5.62,  ...,   8.08, -12.21,   0.42]])\n\n\n\ntr.shape\n\ntorch.Size([50000, 10])\n\n\n\n%time _=matmul(x_train, weights)\n\nCPU times: user 6.59 s, sys: 200 ms, total: 6.79 s\nWall time: 663 ms"
  },
  {
    "objectID": "posts/course22p2/01_matmul.html#einstein-summation",
    "href": "posts/course22p2/01_matmul.html#einstein-summation",
    "title": "01 - Matrix multiplication from foundations",
    "section": "Einstein summation",
    "text": "Einstein summation\nEinstein summation (einsum) is a compact representation for combining products and sums in a general way. The key rules are:\n\nRepeating letters between input arrays means that values along those axes will be multiplied together.\nOmitting a letter from the output means that values along that axis will be summed.\n\n\nm1.shape,m2.shape\n\n(torch.Size([5, 784]), torch.Size([784, 10]))\n\n\n\n# c[i,j] += a[i,k] * b[k,j]\n# c[i,j] = (a[i,:] * b[:,j]).sum()\nmr = torch.einsum('ik,kj->ikj', m1, m2)\nmr.shape\n\ntorch.Size([5, 784, 10])\n\n\n\nmr.sum(1)\n\ntensor([[-10.94,  -0.68,  -7.00,  -4.01,  -2.09,  -3.36,   3.91,  -3.44, -11.47,  -2.12],\n        [ 14.54,   6.00,   2.89,  -4.08,   6.59, -14.74,  -9.28,   2.16, -15.28,  -2.68],\n        [  2.22,  -3.22,  -4.80,  -6.05,  14.17,  -8.98,  -4.79,  -5.44, -20.68,  13.57],\n        [ -6.71,   8.90,  -7.46,  -7.90,   2.70,  -4.73, -11.03, -12.98,  -6.44,   3.64],\n        [ -2.44,  -6.40,  -2.40,  -9.04,  11.18,  -5.77,  -8.92,  -3.79,  -8.98,   5.28]])\n\n\n\ntorch.einsum('ik,kj->ij', m1, m2)\n\ntensor([[-10.94,  -0.68,  -7.00,  -4.01,  -2.09,  -3.36,   3.91,  -3.44, -11.47,  -2.12],\n        [ 14.54,   6.00,   2.89,  -4.08,   6.59, -14.74,  -9.28,   2.16, -15.28,  -2.68],\n        [  2.22,  -3.22,  -4.80,  -6.05,  14.17,  -8.98,  -4.79,  -5.44, -20.68,  13.57],\n        [ -6.71,   8.90,  -7.46,  -7.90,   2.70,  -4.73, -11.03, -12.98,  -6.44,   3.64],\n        [ -2.44,  -6.40,  -2.40,  -9.04,  11.18,  -5.77,  -8.92,  -3.79,  -8.98,   5.28]])\n\n\n\ndef matmul(a,b): return torch.einsum('ik,kj->ij', a, b)\n\n\ntest_close(tr, matmul(x_train, weights), eps=1e-3)\n\n\n%timeit -n 5 _=matmul(x_train, weights)\n\n15.1 ms ± 176 µs per loop (mean ± std. dev. of 7 runs, 5 loops each)"
  },
  {
    "objectID": "posts/course22p2/01_matmul.html#pytorch-op",
    "href": "posts/course22p2/01_matmul.html#pytorch-op",
    "title": "01 - Matrix multiplication from foundations",
    "section": "pytorch op",
    "text": "pytorch op\nWe can use pytorch’s function or operator directly for matrix multiplication.\n\ntest_close(tr, x_train@weights, eps=1e-3)\n\n\n%timeit -n 5 _=torch.matmul(x_train, weights)\n\n15.2 ms ± 96.2 µs per loop (mean ± std. dev. of 7 runs, 5 loops each)"
  },
  {
    "objectID": "posts/course22p2/01_matmul.html#cuda",
    "href": "posts/course22p2/01_matmul.html#cuda",
    "title": "01 - Matrix multiplication from foundations",
    "section": "CUDA",
    "text": "CUDA\n\ndef matmul(grid, a,b,c):\n    i,j = grid\n    if i < c.shape[0] and j < c.shape[1]:\n        tmp = 0.\n        for k in range(a.shape[1]): tmp += a[i, k] * b[k, j]\n        c[i,j] = tmp\n\n\nres = torch.zeros(ar, bc)\nmatmul((0,0), m1, m2, res)\nres\n\ntensor([[-10.94,   0.00,   0.00,   0.00,   0.00,   0.00,   0.00,   0.00,   0.00,   0.00],\n        [  0.00,   0.00,   0.00,   0.00,   0.00,   0.00,   0.00,   0.00,   0.00,   0.00],\n        [  0.00,   0.00,   0.00,   0.00,   0.00,   0.00,   0.00,   0.00,   0.00,   0.00],\n        [  0.00,   0.00,   0.00,   0.00,   0.00,   0.00,   0.00,   0.00,   0.00,   0.00],\n        [  0.00,   0.00,   0.00,   0.00,   0.00,   0.00,   0.00,   0.00,   0.00,   0.00]])\n\n\n\ndef launch_kernel(kernel, grid_x, grid_y, *args, **kwargs):\n    for i in range(grid_x):\n        for j in range(grid_y): kernel((i,j), *args, **kwargs)\n\n\nres = torch.zeros(ar, bc)\nlaunch_kernel(matmul, ar, bc, m1, m2, res)\nres\n\ntensor([[-10.94,  -0.68,  -7.00,  -4.01,  -2.09,  -3.36,   3.91,  -3.44, -11.47,  -2.12],\n        [ 14.54,   6.00,   2.89,  -4.08,   6.59, -14.74,  -9.28,   2.16, -15.28,  -2.68],\n        [  2.22,  -3.22,  -4.80,  -6.05,  14.17,  -8.98,  -4.79,  -5.44, -20.68,  13.57],\n        [ -6.71,   8.90,  -7.46,  -7.90,   2.70,  -4.73, -11.03, -12.98,  -6.44,   3.64],\n        [ -2.44,  -6.40,  -2.40,  -9.04,  11.18,  -5.77,  -8.92,  -3.79,  -8.98,   5.28]])\n\n\n\nfrom numba import cuda\n\n\ndef matmul(grid, a,b,c):\n    i,j = grid\n    if i < c.shape[0] and j < c.shape[1]:\n        tmp = 0.\n        for k in range(a.shape[1]): tmp += a[i, k] * b[k, j]\n        c[i,j] = tmp\n\n\n@cuda.jit\ndef matmul(a,b,c):\n    i, j = cuda.grid(2)\n    if i < c.shape[0] and j < c.shape[1]:\n        tmp = 0.\n        for k in range(a.shape[1]): tmp += a[i, k] * b[k, j]\n        c[i,j] = tmp\n\n\nr = np.zeros(tr.shape)\nm1g,m2g,rg = map(cuda.to_device, (x_train,weights,r))\n\n\nr.shape\n\n(50000, 10)\n\n\n\nTPB = 16\nrr,rc = r.shape\nblockspergrid = (math.ceil(rr / TPB), math.ceil(rc / TPB))\nblockspergrid\n\n(3125, 1)\n\n\n\nmatmul[blockspergrid, (TPB,TPB)](m1g,m2g,rg)\nr = rg.copy_to_host()\ntest_close(tr, r, eps=1e-3)\n\n\n%%timeit -n 10\nmatmul[blockspergrid, (TPB,TPB)](m1g,m2g,rg)\nr = rg.copy_to_host()\n\n3.61 ms ± 708 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n\n\n\nm1c,m2c = x_train.cuda(),weights.cuda()\n\n\nr=(m1c@m2c).cpu()\n\n\n%timeit -n 10 r=(m1c@m2c).cpu()\n\n458 µs ± 93.1 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n\n\nOur broadcasting version was >500ms, and our CUDA version is around 0.5ms, which is another 1000x improvement compared to broadcasting. So our total speedup is around 5 million times!"
  },
  {
    "objectID": "posts/course22p2/03_backprop.html",
    "href": "posts/course22p2/03_backprop.html",
    "title": "03 - The forward and backward passes",
    "section": "",
    "text": "This is not my content it’s a part of Fastai’s From Deep Learning Foundations to Stable Diffusion course. I add some notes for me to understand better thats all. For the source check Fastai course page."
  },
  {
    "objectID": "posts/course22p2/03_backprop.html#the-forward-and-backward-passes",
    "href": "posts/course22p2/03_backprop.html#the-forward-and-backward-passes",
    "title": "03 - The forward and backward passes",
    "section": "The forward and backward passes",
    "text": "The forward and backward passes\n\n\n\ncalculus.png\n\n\n\nimport pickle,gzip,math,os,time,shutil,torch,matplotlib as mpl, numpy as np\nfrom pathlib import Path\nfrom torch import tensor\nfrom fastcore.test import test_close\ntorch.manual_seed(42)\n\nmpl.rcParams['image.cmap'] = 'gray'\ntorch.set_printoptions(precision=2, linewidth=125, sci_mode=False)\nnp.set_printoptions(precision=2, linewidth=125)\n\npath_data = Path('data')\npath_gz = path_data/'mnist.pkl.gz'\nwith gzip.open(path_gz, 'rb') as f: ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding='latin-1')\nx_train, y_train, x_valid, y_valid = map(tensor, [x_train, y_train, x_valid, y_valid])"
  },
  {
    "objectID": "posts/course22p2/03_backprop.html#foundations-version",
    "href": "posts/course22p2/03_backprop.html#foundations-version",
    "title": "03 - The forward and backward passes",
    "section": "Foundations version",
    "text": "Foundations version\n\nBasic architecture\n\nn,m = x_train.shape\nc = y_train.max()+1\nn,m,c\n\n(50000, 784, tensor(10))\n\n\n\n# num hidden\nnh = 50\n\n\nw1 = torch.randn(m,nh)\nb1 = torch.zeros(nh)\nw2 = torch.randn(nh,1)\nb2 = torch.zeros(1)\n\n\ndef lin(x, w, b): return x@w + b\n\n\nt = lin(x_valid, w1, b1)\nt.shape\n\ntorch.Size([10000, 50])\n\n\n\ndef relu(x): return x.clamp_min(0.)\n\n\nt = relu(t)\nt\n\ntensor([[ 0.00, 11.87,  0.00,  ...,  5.48,  2.14, 15.30],\n        [ 5.38, 10.21,  0.00,  ...,  0.88,  0.08, 20.23],\n        [ 3.31,  0.12,  3.10,  ..., 16.89,  0.00, 24.74],\n        ...,\n        [ 4.01, 10.35,  0.00,  ...,  0.23,  0.00, 18.28],\n        [10.62,  0.00, 10.72,  ...,  0.00,  0.00, 18.23],\n        [ 2.84,  0.00,  1.43,  ...,  0.00,  5.75,  2.12]])\n\n\n\ndef model(xb):\n    l1 = lin(xb, w1, b1)\n    l2 = relu(l1)\n    return lin(l2, w2, b2)\n\n\nres = model(x_valid)\nres.shape\n\ntorch.Size([10000, 1])\n\n\n\n\nLoss function: MSE\n(Of course, mse is not a suitable loss function for multi-class classification; we’ll use a better loss function soon. We’ll use mse for now to keep things simple.)\n\nres.shape,y_valid.shape\n\n(torch.Size([10000, 1]), torch.Size([10000]))\n\n\n\n(res-y_valid).shape\n\ntorch.Size([10000, 10000])\n\n\nWe need to get rid of that trailing (,1), in order to use mse.\n\nres[:,0].shape\n\ntorch.Size([10000])\n\n\n\nres.squeeze().shape\n\ntorch.Size([10000])\n\n\n\n(res[:,0]-y_valid).shape\n\ntorch.Size([10000])\n\n\n\ny_train,y_valid = y_train.float(),y_valid.float()\n\npreds = model(x_train)\npreds.shape\n\ntorch.Size([50000, 1])\n\n\n\ndef mse(output, targ): return (output[:,0]-targ).pow(2).mean()\n\n\nmse(preds, y_train)\n\ntensor(4308.76)\n\n\n\n\nGradients and backward pass\n\nfrom sympy import symbols,diff\nx,y = symbols('x y')\ndiff(x**2, x)\n\n\\(\\displaystyle 2 x\\)\n\n\n\ndiff(3*x**2+9, x)\n\n\\(\\displaystyle 6 x\\)\n\n\n\n\n\n\n\n\nSteps of the back-propagation\n\n\n\n\n\n\n\n\n\nchain.png\n\n\n\n\n\n\n\n\nFurther reading\n\n\n\n\ncheck here too for a more detailed explanation of backpropagation. Same thing but includes extra-steps. https://course19.fast.ai/videos/?lesson=8m around 1:53 code here too https://github.com/fastai/course-v3/blob/master/nbs/dl2/02_fully_connected.ipynb\n\nGradient of the relu.\nmse grad( gradient of the loss)\ngradient of the linear layer.\n\n\nThe Intuitive Notion of the Chain Rule\n\nhttps://webspace.ship.edu/msrenault/geogebracalculus/derivative_intuitive_chain_rule.html\n\nThe Matrix Calculus You Need For Deep Learning\n\nhttps://explained.ai/matrix-calculus/\n\n\n\n\n\ndef lin_grad(inp, out, w, b):\n    # grad of matmul with respect to input\n    inp.g = out.g @ w.t()\n    #import pdb; pdb.set_trace()\n    w.g = (inp.unsqueeze(-1) * out.g.unsqueeze(1)).sum(0)\n    b.g = out.g.sum(0)\n\n\ndef forward_and_backward(inp, targ):\n    # forward pass:\n    l1 = lin(inp, w1, b1)\n    l2 = relu(l1)\n    out = lin(l2, w2, b2)\n    diff = out[:,0]-targ\n    loss = diff.pow(2).mean()\n    \n    # backward pass:\n    out.g = 2.*diff[:,None] / inp.shape[0]\n    lin_grad(l2, out, w2, b2)\n    l1.g = (l1>0).float() * l2.g\n    lin_grad(inp, l1, w1, b1)\n\n\nforward_and_backward(x_train, y_train)\n\n\n# Save for testing against later\ndef get_grad(x): return x.g.clone()\nchks = w1,w2,b1,b2,x_train\ngrads = w1g,w2g,b1g,b2g,ig = tuple(map(get_grad, chks))\n\nWe cheat a little bit and use PyTorch autograd to check our results.\n\ndef mkgrad(x): return x.clone().requires_grad_(True)\nptgrads = w12,w22,b12,b22,xt2 = tuple(map(mkgrad, chks))\n\n\ndef forward(inp, targ):\n    l1 = lin(inp, w12, b12)\n    l2 = relu(l1)\n    out = lin(l2, w22, b22)\n    return mse(out, targ)\n\n\nloss = forward(xt2, y_train)\nloss.backward()\n\n\nfor a,b in zip(grads, ptgrads): test_close(a, b.grad, eps=0.01)"
  },
  {
    "objectID": "posts/course22p2/03_backprop.html#refactor-model",
    "href": "posts/course22p2/03_backprop.html#refactor-model",
    "title": "03 - The forward and backward passes",
    "section": "Refactor model",
    "text": "Refactor model\n\nLayers as classes\n\nclass Relu():\n    def __call__(self, inp):\n        self.inp = inp\n        self.out = inp.clamp_min(0.)\n        return self.out\n    \n    def backward(self): self.inp.g = (self.inp>0).float() * self.out.g\n\n\nclass Lin():\n    def __init__(self, w, b): self.w,self.b = w,b\n\n    def __call__(self, inp):\n        self.inp = inp\n        self.out = lin(inp, self.w, self.b)\n        return self.out\n\n    def backward(self):\n        self.inp.g = self.out.g @ self.w.t()\n        #self.w.g = self.inp.t() @ self.out.g\n        #self.b.g = self.out.g.sum(0)\n\n\nclass Mse():\n    def __call__(self, inp, targ):\n        self.inp,self.targ = inp,targ\n        self.out = mse(inp, targ)\n        return self.out\n    \n    def backward(self):\n        self.inp.g = 2. * (self.inp.squeeze() - self.targ).unsqueeze(-1) / self.targ.shape[0]\n\n\nclass Model():\n    def __init__(self, w1, b1, w2, b2):\n        self.layers = [Lin(w1,b1), Relu(), Lin(w2,b2)]\n        self.loss = Mse()\n        \n    def __call__(self, x, targ):\n        for l in self.layers: x = l(x)\n        return self.loss(x, targ)\n    \n    def backward(self):\n        self.loss.backward()\n        for l in reversed(self.layers): l.backward()\n\n\nmodel = Model(w1, b1, w2, b2)\n\n\nloss = model(x_train, y_train)\n\n\nmodel.backward()\n\n\ntest_close(w2g, w2.g, eps=0.01)\ntest_close(b2g, b2.g, eps=0.01)\ntest_close(w1g, w1.g, eps=0.01)\ntest_close(b1g, b1.g, eps=0.01)\ntest_close(ig, x_train.g, eps=0.01)\n\n\n\nModule.forward()\n\nclass Module():\n    def __call__(self, *args):\n        self.args = args\n        self.out = self.forward(*args)\n        return self.out\n\n    def forward(self): raise Exception('not implemented')\n    def backward(self): self.bwd(self.out, *self.args)\n    def bwd(self): raise Exception('not implemented')\n\n\nclass Relu(Module):\n    def forward(self, inp): return inp.clamp_min(0.)\n    def bwd(self, out, inp): inp.g = (inp>0).float() * out.g\n\n\nclass Lin(Module):\n    def __init__(self, w, b): self.w,self.b = w,b\n    def forward(self, inp): return inp@self.w + self.b\n    def bwd(self, out, inp):\n        inp.g = self.out.g @ self.w.t()\n        self.w.g = inp.t() @ self.out.g\n        self.b.g = self.out.g.sum(0)\n\n\nclass Mse(Module):\n    def forward (self, inp, targ): return (inp.squeeze() - targ).pow(2).mean()\n    def bwd(self, out, inp, targ): inp.g = 2*(inp.squeeze()-targ).unsqueeze(-1) / targ.shape[0]\n\n\nmodel = Model(w1, b1, w2, b2)\n\n\nloss = model(x_train, y_train)\n\n\nmodel.backward()\n\n\ntest_close(w2g, w2.g, eps=0.01)\ntest_close(b2g, b2.g, eps=0.01)\ntest_close(w1g, w1.g, eps=0.01)\ntest_close(b1g, b1.g, eps=0.01)\ntest_close(ig, x_train.g, eps=0.01)\n\n\n\nAutograd\n\nfrom torch import nn\nimport torch.nn.functional as F\n\n\nclass Linear(nn.Module):\n    def __init__(self, n_in, n_out):\n        super().__init__()\n        self.w = torch.randn(n_in,n_out).requires_grad_()\n        self.b = torch.zeros(n_out).requires_grad_()\n    def forward(self, inp): return inp@self.w + self.b\n\n\nclass Model(nn.Module):\n    def __init__(self, n_in, nh, n_out):\n        super().__init__()\n        self.layers = [Linear(n_in,nh), nn.ReLU(), Linear(nh,n_out)]\n        \n    def __call__(self, x, targ):\n        for l in self.layers: x = l(x)\n        return F.mse_loss(x, targ[:,None])\n\n\nmodel = Model(m, nh, 1)\nloss = model(x_train, y_train)\nloss.backward()\n\n\nl0 = model.layers[0]\nl0.b.grad\n\ntensor([-19.60,  -2.40,  -0.12,   1.99,  12.78, -15.32, -18.45,   0.35,   3.75,  14.67,  10.81,  12.20,  -2.95, -28.33,\n          0.76,  69.15, -21.86,  49.78,  -7.08,   1.45,  25.20,  11.27, -18.15, -13.13, -17.69, -10.42,  -0.13, -18.89,\n        -34.81,  -0.84,  40.89,   4.45,  62.35,  31.70,  55.15,  45.13,   3.25,  12.75,  12.45,  -1.41,   4.55,  -6.02,\n        -62.51,  -1.89,  -1.41,   7.00,   0.49,  18.72,  -4.84,  -6.52])"
  },
  {
    "objectID": "posts/course22p2/02_meanshift.html",
    "href": "posts/course22p2/02_meanshift.html",
    "title": "02 - Mean Shift",
    "section": "",
    "text": "This is not my content it’s a part of Fastai’s From Deep Learning Foundations to Stable Diffusion course. I add some notes for me to understand better thats all. For the source check Fastai course page."
  },
  {
    "objectID": "posts/course22p2/02_meanshift.html#create-data",
    "href": "posts/course22p2/02_meanshift.html#create-data",
    "title": "02 - Mean Shift",
    "section": "Create data",
    "text": "Create data\n\nn_clusters=6\nn_samples =250\n\nTo generate our data, we’re going to pick 6 random points, which we’ll call centroids, and for each point we’re going to generate 250 random points about it.\n\ncentroids = torch.rand(n_clusters, 2)*70-35\n\n\ncentroids\n\ntensor([[ 26.759,  29.050],\n        [ -8.200,  32.151],\n        [ -7.669,   7.063],\n        [-17.040,  20.555],\n        [ 30.854, -25.677],\n        [ 30.422,   6.551]])\n\n\n\nfrom torch.distributions.multivariate_normal import MultivariateNormal\nfrom torch import tensor\n\n\n\n\n\n\n\nMore info for covariance matrix is on the lesson 9B.\n\n\n\n\n\n\n\ndef sample(m): return MultivariateNormal(m, torch.diag(tensor([5.,5.]))).sample((n_samples,))\n\n\nslices = [sample(c) for c in centroids]\ndata = torch.cat(slices)\ndata.shape\n\ntorch.Size([1500, 2])\n\n\nBelow we can see each centroid marked w/ X, and the coloring associated to each respective cluster.\n\ndef plot_data(centroids, data, n_samples, ax=None):\n    if ax is None: _,ax = plt.subplots()\n    for i, centroid in enumerate(centroids):\n        samples = data[i*n_samples:(i+1)*n_samples]\n        ax.scatter(samples[:,0], samples[:,1], s=1)\n        ax.plot(*centroid, markersize=10, marker=\"x\", color='k', mew=5)\n        ax.plot(*centroid, markersize=5, marker=\"x\", color='m', mew=2)\n\n\nplot_data(centroids, data, n_samples)"
  },
  {
    "objectID": "posts/course22p2/02_meanshift.html#mean-shift",
    "href": "posts/course22p2/02_meanshift.html#mean-shift",
    "title": "02 - Mean Shift",
    "section": "Mean shift",
    "text": "Mean shift\nMost people that have come across clustering algorithms have learnt about k-means. Mean shift clustering is a newer and less well-known approach, but it has some important advantages: * It doesn’t require selecting the number of clusters in advance, but instead just requires a bandwidth to be specified, which can be easily chosen automatically * It can handle clusters of any shape, whereas k-means (without using special extensions) requires that clusters be roughly ball shaped.\nThe algorithm is as follows: * For each data point x in the sample X, find the distance between that point x and every other point in X * Create weights for each point in X by using the Gaussian kernel of that point’s distance to x * This weighting approach penalizes points further away from x * The rate at which the weights fall to zero is determined by the bandwidth, which is the standard deviation of the Gaussian * Update x as the weighted average of all other points in X, weighted based on the previous step\nThis will iteratively push points that are close together even closer until they are next to each other.\n\nmidp = data.mean(0)\nmidp\n\ntensor([ 9.222, 11.604])\n\n\n\nplot_data([midp]*6, data, n_samples)\n\n\n\n\nSo here’s the definition of the gaussian kernel, which you may remember from high school… This person at the science march certainly remembered!\n\n\ndef gaussian(d, bw): return torch.exp(-0.5*((d/bw))**2) / (bw*math.sqrt(2*math.pi))\n\n\ndef plot_func(f):\n    x = torch.linspace(0,10,100)\n    plt.plot(x, f(x))\n\n\nplot_func(partial(gaussian, bw=2.5))\n\n\n\n\n:::{{ callout-note }} ## Partial functions are cool :::\n\npartial\n\nfunctools.partial\n\n\nIn our implementation, we choose the bandwidth to be 2.5.\nOne easy way to choose bandwidth is to find which bandwidth covers one third of the data.\n\ndef tri(d, i): return (-d+i).clamp_min(0)/i\n\n\nplot_func(partial(tri, i=8))\n\n\n\n\n\nX = data.clone()\nx = data[0]\n\n\nx\n\ntensor([26.204, 26.349])\n\n\n\nx.shape,X.shape,x[None].shape\n\n(torch.Size([2]), torch.Size([1500, 2]), torch.Size([1, 2]))\n\n\n\n(x[None]-X)[:8]\n\ntensor([[ 0.000,  0.000],\n        [ 0.513, -3.865],\n        [-4.227, -2.345],\n        [ 0.557, -3.685],\n        [-5.033, -3.745],\n        [-4.073, -0.638],\n        [-3.415, -5.601],\n        [-1.920, -5.686]])\n\n\n\n(x-X)[:8]\n\ntensor([[ 0.000,  0.000],\n        [ 0.513, -3.865],\n        [-4.227, -2.345],\n        [ 0.557, -3.685],\n        [-5.033, -3.745],\n        [-4.073, -0.638],\n        [-3.415, -5.601],\n        [-1.920, -5.686]])\n\n\n\n# rewrite using torch.einsum\ndist = ((x-X)**2).sum(1).sqrt()\ndist[:8]\n\ntensor([0.000, 3.899, 4.834, 3.726, 6.273, 4.122, 6.560, 6.002])\n\n\n\nweight = gaussian(dist, 2.5)\nweight\n\ntensor([    0.160,     0.047,     0.025,  ...,     0.000,     0.000,     0.000])\n\n\n\nweight.shape,X.shape\n\n(torch.Size([1500]), torch.Size([1500, 2]))\n\n\n\nweight[:,None].shape\n\ntorch.Size([1500, 1])\n\n\n\nweight[:,None]*X\n\ntensor([[    4.182,     4.205],\n        [    1.215,     1.429],\n        [    0.749,     0.706],\n        ...,\n        [    0.000,     0.000],\n        [    0.000,     0.000],\n        [    0.000,     0.000]])\n\n\n\ndef one_update(X):\n    for i, x in enumerate(X):\n        dist = torch.sqrt(((x-X)**2).sum(1))\n#         weight = gaussian(dist, 2.5)\n        weight = tri(dist, 8)\n        X[i] = (weight[:,None]*X).sum(0)/weight.sum()\n\n\ndef meanshift(data):\n    X = data.clone()\n    for it in range(5): one_update(X)\n    return X\n\n\n%time X=meanshift(data)\n\nCPU times: user 453 ms, sys: 0 ns, total: 453 ms\nWall time: 452 ms\n\n\n\nplot_data(centroids+2, X, n_samples)"
  },
  {
    "objectID": "posts/course22p2/02_meanshift.html#animation",
    "href": "posts/course22p2/02_meanshift.html#animation",
    "title": "02 - Mean Shift",
    "section": "Animation",
    "text": "Animation\n\nfrom matplotlib.animation import FuncAnimation\nfrom IPython.display import HTML\n\n\ndef do_one(d):\n    if d: one_update(X)\n    ax.clear()\n    plot_data(centroids+2, X, n_samples, ax=ax)\n\n\n# create your own animation\nX = data.clone()\nfig,ax = plt.subplots()\nani = FuncAnimation(fig, do_one, frames=5, interval=500, repeat=False)\nplt.close()\nHTML(ani.to_jshtml())\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect"
  },
  {
    "objectID": "posts/course22p2/02_meanshift.html#gpu-batched-algorithm",
    "href": "posts/course22p2/02_meanshift.html#gpu-batched-algorithm",
    "title": "02 - Mean Shift",
    "section": "GPU batched algorithm",
    "text": "GPU batched algorithm\nTo truly accelerate the algorithm, we need to be performing updates on a batch of points per iteration, instead of just one as we were doing.\n\nbs=5\nX = data.clone()\nx = X[:bs]\nx.shape,X.shape\n\n(torch.Size([5, 2]), torch.Size([1500, 2]))\n\n\n\ndef dist_b(a,b): return (((a[None]-b[:,None])**2).sum(2)).sqrt()\n\n\ndist_b(X, x)\n\ntensor([[ 0.000,  3.899,  4.834,  ..., 17.628, 22.610, 21.617],\n        [ 3.899,  0.000,  4.978,  ..., 21.499, 26.508, 25.500],\n        [ 4.834,  4.978,  0.000,  ..., 19.373, 24.757, 23.396],\n        [ 3.726,  0.185,  4.969,  ..., 21.335, 26.336, 25.333],\n        [ 6.273,  5.547,  1.615,  ..., 20.775, 26.201, 24.785]])\n\n\n\ndist_b(X, x).shape\n\ntorch.Size([5, 1500])\n\n\n\nX[None,:].shape, x[:,None].shape, (X[None,:]-x[:,None]).shape\n\n(torch.Size([1, 1500, 2]), torch.Size([5, 1, 2]), torch.Size([5, 1500, 2]))\n\n\n\nweight = gaussian(dist_b(X, x), 2)\nweight\n\ntensor([[    0.199,     0.030,     0.011,  ...,     0.000,     0.000,     0.000],\n        [    0.030,     0.199,     0.009,  ...,     0.000,     0.000,     0.000],\n        [    0.011,     0.009,     0.199,  ...,     0.000,     0.000,     0.000],\n        [    0.035,     0.199,     0.009,  ...,     0.000,     0.000,     0.000],\n        [    0.001,     0.004,     0.144,  ...,     0.000,     0.000,     0.000]])\n\n\n\nweight.shape,X.shape\n\n(torch.Size([5, 1500]), torch.Size([1500, 2]))\n\n\n\nweight[...,None].shape, X[None].shape\n\n(torch.Size([5, 1500, 1]), torch.Size([1, 1500, 2]))\n\n\n\nnum = (weight[...,None]*X[None]).sum(1)\nnum.shape\n\ntorch.Size([5, 2])\n\n\n\nnum\n\ntensor([[367.870, 386.231],\n        [518.332, 588.680],\n        [329.665, 330.782],\n        [527.617, 598.217],\n        [231.302, 234.155]])\n\n\n\ntorch.einsum('ij,jk->ik', weight, X)\n\ntensor([[367.870, 386.231],\n        [518.332, 588.680],\n        [329.665, 330.782],\n        [527.617, 598.218],\n        [231.302, 234.155]])\n\n\n\nweight@X\n\ntensor([[367.870, 386.231],\n        [518.332, 588.680],\n        [329.665, 330.782],\n        [527.617, 598.218],\n        [231.302, 234.155]])\n\n\n\ndiv = weight.sum(1, keepdim=True)\ndiv.shape\n\ntorch.Size([5, 1])\n\n\n\nnum/div\n\ntensor([[26.376, 27.692],\n        [26.101, 29.643],\n        [28.892, 28.990],\n        [26.071, 29.559],\n        [29.323, 29.685]])\n\n\n\ndef meanshift(data, bs=500):\n    n = len(data)\n    X = data.clone()\n    for it in range(5):\n        for i in range(0, n, bs):\n            s = slice(i, min(i+bs,n))\n            weight = gaussian(dist_b(X, X[s]), 2.5)\n#             weight = tri(dist_b(X, X[s]), 8)\n            div = weight.sum(1, keepdim=True)\n            X[s] = weight@X/div\n    return X\n\nAlthough each iteration still has to launch a new cuda kernel, there are now fewer iterations, and the acceleration from updating a batch of points more than makes up for it.\n\ndata = data.cuda()\n\n\nX = meanshift(data).cpu()\n\n\n%timeit -n 5 _=meanshift(data, 1250).cpu()\n\n2 ms ± 226 µs per loop (mean ± std. dev. of 7 runs, 5 loops each)\n\n\n\nplot_data(centroids+2, X, n_samples)\n\n\n\n\nHomework: implement k-means clustering, dbscan, locality sensitive hashing, or some other clustering, fast nearest neighbors, or similar algorithm of your choice, on the GPU. Check if your version is faster than a pure python or CPU version.\nBonus: Implement it in APL too!\nSuper bonus: Invent a new meanshift algorithm which picks only the closest points, to avoid quadratic time.\nSuper super bonus: Publish a paper that describes it :D"
  },
  {
    "objectID": "posts/myfirstNN/2022-01-15-myFirstNN.html",
    "href": "posts/myfirstNN/2022-01-15-myFirstNN.html",
    "title": "Tiny bug world with neuro evolution (2018)",
    "section": "",
    "text": "This is from 2018, tutorials and trainings aside my first attempt for training a neural network. It does not have a traditional loss function or optimization method but it uses neuroevolution for training. I use p5.JS for the visualization and tensorflow.JS for the model.\nGithub Link is here"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  }
]